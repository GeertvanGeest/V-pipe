import sys
from pathlib import Path

import pandas as pd

from snakemake.utils import Paramspace
from snakemake.io import Namedlist


# setup config
configfile: "config/config.yaml"


# setup paramspace
df_params = pd.read_csv(config["params_path"], comment="#")
paramspace = Paramspace(df_params, filename_params="*", filename_sep="__")

# method selection
if config["method_list"] is None:
    (method_list,) = glob_wildcards(srcdir("../resources/method_definitions/{method}.py"))
else:
    method_list = config["method_list"]

print(method_list, file=sys.stderr)


# group methods into local (produces VCF) and global (produces FASTA)
method_list_local = []
method_list_global = []

for method in method_list:
    group_prefix = "# GROUP:"

    fname_method = srcdir(f"../resources/method_definitions/{method}.py")
    with open(fname_method) as fd:
        for line in fd.readlines():
            if not line.startswith(group_prefix):
                continue

            group = line[len(group_prefix) :].strip()
            break

    if group == "local":
        method_list_local.append(method)
    elif group == "global":
        method_list_global.append(method)
    else:
        raise RuntimeError(f"Invalid group '{group}' for method '{method}'")


# misc setup
sequencing_mode = paramspace["seq_mode"][0]
if sequencing_mode.startswith("amplicon"):
    sequencing_mode = sequencing_mode.split(":")[
        0
    ]  # TODO: Allow different sequencing_modes in parameter file


# helper functions
def get_generated_conda_env(wildcards, input):
    # retrieve conda dependencies from script
    conda_dep_prefix = "# CONDA:"

    conda_dep_list = []
    with open(input.script) as fd:
        for line in fd.readlines():
            if not line.startswith(conda_dep_prefix):
                continue

            conda_dep_list.append(line[len(conda_dep_prefix) :].strip())

    # retrieve pip dependencies from script
    pip_dep_prefix = "# PIP:"

    pip_dep_list = []
    with open(input.script) as fd:
        for line in fd.readlines():
            if not line.startswith(pip_dep_prefix):
                continue

            pip_dep_list.append(line[len(pip_dep_prefix) :].strip())

    # format conda env file
    conda_env = """channels:
  - hcc
  - broad-viral
  - conda-forge
  - bioconda
  - defaults
dependencies:"""

    if len(conda_dep_list) == 0 and len(pip_dep_list) == 0:
        conda_env += " []"
    else:
        if len(conda_dep_list) > 0:
            conda_env += "\n  - " + "\n  - ".join(conda_dep_list)

        if len(pip_dep_list) > 0:
            conda_env += "\n  - python=3.9\n"
            conda_env += "  - pip\n"
            conda_env += "  - pip:\n    - " + "\n    - ".join(pip_dep_list)

    print(f'Generated conda env for "{input.script}":', file=sys.stderr)
    print(conda_env, file=sys.stderr)

    # save conda env
    conda_prefix = Path("results/envs/")
    conda_prefix.mkdir(parents=True, exist_ok=True)

    conda_env_path = conda_prefix / f"{Path(input.script).name}.yaml"
    conda_env_path.write_text(conda_env)

    return Path("..") / conda_env_path


# generate conda envs
for method in method_list:
    get_generated_conda_env(
        None,
        Namedlist(fromdict={"script": srcdir(f"../resources/method_definitions/{method}.py")}),
    )


# rule definitions
rule all:
    input:
        "results/performance_measures/local/" if len(method_list_local) > 0 else [],
        "results/performance_measures/global/" if len(method_list_global) > 0 else [],
        #"results/haplotype_populations/" if config['haplotype_generation'] == 'distance' else None,
        expand(
            "results/read_statistics/{params}/replicates/{replicate}/",
            params=paramspace.instance_patterns,
            replicate=range(config["replicate_count"]),
        ),


rule generate_haplotypes:
    output:
        fname_reference=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reference.fasta",
        fname_groundtruth=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/ground_truth.csv",
        fname_fasta=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/haplotypes.fasta",
        dname_work=directory(
            f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/work/"
        ),
    params:
        params=paramspace.instance,
        haplotype_generation=config["haplotype_generation"],
    conda:
        "envs/simulate_reads.yaml"
    script:
        "scripts/generate_haplotypes.py"


rule shotgun_simulation:
    input:
        dname_work=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/work/",
    output:
        fname_fastq=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.shotgun.fastq",
        fname_bam=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.shotgun.bam",
    params:
        params=paramspace.instance,
        haplotype_generation=config["haplotype_generation"],
    conda:
        "envs/simulate_reads.yaml"
    script:
        "scripts/shotgun_simulation.py"


if config["haplotype_generation"] == "distance":

    rule collect_haplo_populations_visualizations:
        input:
            dname_work=[
                f"results/simulated_reads/{params}/replicates/{replicate}/work/"
                for params in paramspace.instance_patterns
                for replicate in range(config["replicate_count"])
            ],
        output:
            dname_out=directory(f"results/haplotype_populations/"),
        script:
            "scripts/collect_haplo_populations.py"


rule simulate_scheme:
    conda:
        "envs/split.yaml"
    input:
        fname_reference=rules.generate_haplotypes.output.fname_reference,
    output:
        fname_insert_bed=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/scheme/reference.insert.bed",
        dname_out=directory(
            f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/scheme/"
        ),
    params:
        params=paramspace.instance,
    script:
        "scripts/simulate_scheme.py"


rule amplicon_simulation:
    input:
        dname_work=rules.generate_haplotypes.output.dname_work,
        fname_insert_bed=rules.simulate_scheme.output.fname_insert_bed,
    output:
        fname_fastq_R1=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.amplicon.R1.fastq",
        fname_fastq_R2=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.amplicon.R2.fastq",
        fname_bam=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads_merged.amplicon.bam",
    params:
        params=paramspace.instance,
        haplotype_generation=config["haplotype_generation"],
    conda:
        "envs/simulate_reads.yaml"
    script:
        "scripts/amplicon_simulation.py"


rule flash:
    input:
        fname_fastq_R1=rules.amplicon_simulation.output.fname_fastq_R1,
        fname_fastq_R2=rules.amplicon_simulation.output.fname_fastq_R2,
    output:
        fname_fastq_merged=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/flash/reads_merged.extendedFrags.fastq",
        dname_out=directory(
            f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/flash/"
        ),
    conda:
        "envs/split.yaml"
    shell:
        """
        flash \
          {input.fname_fastq_R1} \
          {input.fname_fastq_R2} \
          -r 250 \
          -f 400 \
          -s 40 \
          --allow-outies \
          --output-prefix=reads_merged \
          --output-directory={output.dname_out}
        """


rule alignment_merged:
    input:
        fname_reference=rules.generate_haplotypes.output.fname_reference,
        fname_fastq_merged=rules.flash.output.fname_fastq_merged,
    output:
        fname_bam=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.amplicon.bam",
    conda:
        "envs/split.yaml"
    shell:
        """
        bwa index {input.fname_reference}
        bwa mem {input.fname_reference} {input.fname_fastq_merged} > {output.fname_bam}
        samtools sort -o {output.fname_bam} {output.fname_bam}
        """


rule samtools_index:
    input:
        f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.{{seq_mode}}.bam",
    output:
        f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.{{seq_mode}}.bam.bai",
    wrapper:
        "v1.3.2/bio/samtools/index"


rule read_statistics:
    input:
        fname_bam=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.{{seq_mode}}.bam",
        fname_bam_index=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.{{seq_mode}}.bam.bai",
    output:
        outdir=directory(
            f"results/read_statistics/{paramspace.wildcard_pattern}/replicates/{{replicate}}/"
        ),
    conda:
        "envs/read_statistics.yaml"
    script:
        "scripts/read_statistics.py"


rule run_method_local:
    input:
        script=srcdir("../resources/method_definitions/{method}.py"),
        fname_bam=lambda wildcards: f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads_merged.{{seq_mode}}.bam"
        if wildcards.method == "shorah_canary"
        else f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.{{seq_mode}}.bam",
        fname_bam_index=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.{{seq_mode}}.bam.bai",
        fname_reference=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reference.fasta",
        fname_insert_bed=lambda wildcards: f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/scheme/reference.insert.bed"
        if wildcards.seq_mode == "amplicon"
        else [],
    output:
        fname_result=f"results/method_runs/{paramspace.wildcard_pattern}/{{method}}/replicates/{{replicate}}/snvs.vcf",
        dname_work=directory(
            f"results/method_runs/{paramspace.wildcard_pattern}/{{method}}/replicates/{{replicate}}/work/"
        ),
    benchmark:
        f"results/method_runs/{paramspace.wildcard_pattern}/{{method,{'|'.join(['markertoavoidemptyregex'] + method_list_local)}}}/replicates/{{replicate}}/benchmark.tsv"
    params:
        script_path=lambda wildcards, input: input.script,
        # env_path=get_generated_conda_env,
    conda:
        # "{params.env_path}"
        "../results/envs/{method}.py.yaml"
    script:
        "{params.script_path}"


use rule run_method_local as run_method_global with:
    output:
        fname_result=f"results/method_runs/{paramspace.wildcard_pattern}/{{method}}/replicates/{{replicate}}/haplotypes.fasta",
        dname_work=directory(
            f"results/method_runs/{paramspace.wildcard_pattern}/{{method}}/replicates/{{replicate}}/work/"
        ),
    benchmark:
        f"results/method_runs/{paramspace.wildcard_pattern}/{{method,{'|'.join(['markertoavoidemptyregex'] + method_list_global)}}}/replicates/{{replicate}}/benchmark.tsv"

rule haplotypes_stats:
    input:
        fname_reference=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reference.fasta",
        fname_groundtruth=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/ground_truth.csv",
    output:
        fname=f"results/haplo_stats/{paramspace.wildcard_pattern}/replicates/{{replicate}}/haplotypes_stats.csv"
    conda:
        "envs/haplotype_stats.yaml"
    script:
        "scripts/haplotypes_stats.py"


rule performance_measures_local:
    input:
        vcf_list=[
            f"results/method_runs/{params}/{method}/replicates/{replicate}/snvs.vcf"
            for params in paramspace.instance_patterns
            for method in method_list_local
            for replicate in range(config["replicate_count"])
        ],
        # we also include `method_list_local` to align with `vcf_list`
        groundtruth_list=[
            f"results/simulated_reads/{params}/replicates/{replicate}/ground_truth.csv"
            for params in paramspace.instance_patterns
            for method in method_list_local
            for replicate in range(config["replicate_count"])
        ],
        benchmark_list=[
            f"results/method_runs/{params}/{method}/replicates/{replicate}/benchmark.tsv"
            for params in paramspace.instance_patterns
            for method in method_list_local
            for replicate in range(config["replicate_count"])
        ],
        haplostats_list=[
            f"results/haplo_stats/{params}/replicates/{replicate}/haplotypes_stats.csv"
            for params in paramspace.instance_patterns
            for replicate in range(config["replicate_count"])
        ],
    output:
        dname_out=directory("results/performance_measures/local/"),
    conda:
        "envs/performance_measures.yaml"
    script:
        "scripts/performance_measures_local.py"


rule performance_measures_global:
    input:
        predicted_haplos_list=[
            f"results/method_runs/{params}/{method}/replicates/{replicate}/haplotypes.fasta"
            for params in paramspace.instance_patterns
            for method in method_list_global
            for replicate in range(config["replicate_count"])
        ],
        true_haplos_list=[
            f"results/simulated_reads/{params}/replicates/{replicate}/haplotypes.fasta"
            for params in paramspace.instance_patterns
            for method in method_list_global
            for replicate in range(config["replicate_count"])
        ],
    output:
        dname_out=directory("results/performance_measures/global/"),
    conda:
        "envs/performance_measures.yaml"
    script:
        "scripts/performance_measures_global.py"
