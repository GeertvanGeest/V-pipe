from pathlib import Path

import pandas as pd

from snakemake.utils import Paramspace


# setup config
configfile: "config/config.yaml"


# setup paramspace
df_params = pd.read_csv("config/params.csv")
paramspace = Paramspace(df_params, filename_params="*")

# method selection
if config["method_list"] is None:
    (method_list,) = glob_wildcards("resources/method_definitions/{method}.py")
else:
    method_list = config["method_list"]

print(method_list)


# helper functions
def get_generated_conda_env(wildcards, input):
    # retrieve conda dependencies from script
    conda_dep_prefix = "# CONDA:"

    conda_dep_list = []
    with open(input.script) as fd:
        for line in fd.readlines():
            if not line.startswith(conda_dep_prefix):
                continue

            conda_dep_list.extend(
                e.strip() for e in line[len(conda_dep_prefix):].split(",")
            )

    # format conda env file
    conda_env = f"""
channels:
  - conda-forge
  - bioconda
  - defaults
dependencies: {conda_dep_list}
    """

    # save conda env
    conda_prefix = Path("results/envs/")
    conda_prefix.mkdir(parents=True, exist_ok=True)

    conda_env_path = conda_prefix / f"{Path(input.script).name}.yaml"
    conda_env_path.write_text(conda_env)

    return Path("..") / conda_env_path


# rule definitions
rule all:
    input:
        "results/performance_measures/",


rule simulate_reads:
    output:
        fname_fastq=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.fastq",
        fname_bam=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.bam",
        fname_reference=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reference.fasta",
        fname_groundtruth=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/ground_truth.csv",
        dname_work=directory(
            f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/work/"
        ),
    params:
        params=paramspace.instance,
    conda:
        "envs/simulate_reads.yaml"
    script:
        "scripts/simulate_reads.py"


rule run_method:
    input:
        script="resources/method_definitions/{method}.py",
        fname_bam=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reads.bam",
        fname_reference=f"results/simulated_reads/{paramspace.wildcard_pattern}/replicates/{{replicate}}/reference.fasta",
    output:
        fname_results=f"results/method_runs/{paramspace.wildcard_pattern}/{{method}}/replicates/{{replicate}}/snvs.vcf",
        dname_work=directory(
            f"results/method_runs/{paramspace.wildcard_pattern}/{{method}}/replicates/{{replicate}}/work/"
        ),
    benchmark:
        f"results/method_runs/{paramspace.wildcard_pattern}/{{method}}/replicates/{{replicate}}/benchmark.tsv"
    params:
        script_path=lambda wildcards, input: "../" + input.script,
        env_path=get_generated_conda_env,
    conda:
        "{params.env_path}"
    script:
        "{params.script_path}"


rule performance_measures:
    input:
        vcf_list=[
            f"results/method_runs/{params}/{method}/replicates/{replicate}/snvs.vcf"
            for params in paramspace.instance_patterns
            for method in method_list
            for replicate in range(config["replicate_count"])
        ],
        # we also include `method_list` to align with `vcf_list`
        groundtruth_list=[
            f"results/simulated_reads/{params}/replicates/{replicate}/ground_truth.csv"
            for params in paramspace.instance_patterns
            for method in method_list
            for replicate in range(config["replicate_count"])
        ],
        benchmark_list=[
            f"results/method_runs/{params}/{method}/replicates/{replicate}/benchmark.tsv"
            for params in paramspace.instance_patterns
            for method in method_list
            for replicate in range(config["replicate_count"])
        ],
    output:
        dname_out=directory("results/performance_measures/"),
    conda:
        "envs/performance_measures.yaml"
    script:
        "scripts/performance_measures.py"
